Excelente! üí°
Aqui est√° o **diagrama de arquitetura em Mermaid** mostrando o fluxo completo da solu√ß√£o da **Obsrv** ‚Äî da coleta dos dados (scraping) at√© o envio de notifica√ß√µes e disponibiliza√ß√£o via API/dashboard.

Voc√™ pode copiar este bloco diretamente em um README.md ou em ferramentas como o [Mermaid Live Editor](https://mermaid.live/) para visualizar graficamente.

---

```mermaid
flowchart LR
    subgraph Client["Cliente / Usu√°rio"]
        UI["Dashboard Web / Portal"]
        APIClient["API Client / Webhook Receiver"]
    end

    subgraph Scheduler["Orquestra√ß√£o"]
        Cron["EventBridge / CronJob (Agendador)"]
        Queue["Fila de Jobs (SQS / Kafka / Redis Streams)"]
    end

    subgraph ScraperCluster["Workers de Coleta"]
        W1["Scraper (Requests / BS4)"]
        W2["Scraper (Playwright Headless)"]
        Parser["Normalizador de Dados"]
    end

    subgraph Storage["Armazenamento"]
        DB[(PostgreSQL / TimescaleDB)]
        S3[(S3 / GCS - Raw HTML + Screenshots)]
        Cache[(Redis - Cache / Rate Limit / Locks)]
    end

    subgraph Analytics["Processamento e Eventos"]
        Diff["Motor de Compara√ß√£o (Diff Engine)"]
        Events["Change Events (Fila de Eventos)"]
    end

    subgraph Notification["Servi√ßo de Notifica√ß√µes"]
        WS["WebSocket Server / Socket.IO"]
        Push["WebPush / Email / Webhook"]
    end

    subgraph Observability["Monitoramento e DevOps"]
        Logs["Logs estruturados (ELK / OpenSearch)"]
        Metrics["M√©tricas (Prometheus + Grafana)"]
        Traces["Tracing (Jaeger / OTEL)"]
    end

    Client -->|Cadastra URLs / Regras| API["API Gateway / Backend"]
    API --> DB
    API --> Queue

    Cron --> Queue
    Queue --> W1
    Queue --> W2

    W1 --> Parser
    W2 --> Parser

    Parser -->|Normalizado| DB
    Parser -->|Raw HTML / Screenshot| S3

    DB --> Diff
    Diff --> Events

    Events --> Notification
    Notification --> WS
    Notification --> Push
    WS --> UI
    Push --> APIClient

    Diff --> DB
    Cache --> ScraperCluster

    Logs --- ScraperCluster
    Logs --- API
    Logs --- Notification
    Metrics --- All[("Todos os Servi√ßos")]
    Traces --- All

    classDef compute fill:#b3e0ff,stroke:#0366d6,stroke-width:1px;
    classDef storage fill:#ffe599,stroke:#b45f06,stroke-width:1px;
    classDef notify fill:#b6d7a8,stroke:#38761d,stroke-width:1px;
    classDef client fill:#f4cccc,stroke:#990000,stroke-width:1px;
    classDef infra fill:#d9d2e9,stroke:#674ea7,stroke-width:1px;

    class W1,W2,Parser,Diff,Events compute;
    class DB,S3,Cache storage;
    class Notification,WS,Push notify;
    class Client,UI,APIClient client;
    class Scheduler,Cron,Queue,Observability,Logs,Metrics,Traces infra;
```

---

## üß≠ Interpreta√ß√£o r√°pida

* **Scheduler** ‚Üí agenda tarefas di√°rias (via EventBridge/CronJob) e coloca jobs na **fila**.
* **ScraperCluster** ‚Üí executa scrapers (HTTP simples ou headless) e envia resultados normalizados ao **storage**.
* **Storage** ‚Üí guarda JSON normalizado (Postgres) + HTML/screenshot bruto (S3).
* **Diff Engine** ‚Üí compara snapshots e gera eventos de mudan√ßa.
* **Notification Service** ‚Üí envia notifica√ß√µes em tempo real (WebSocket, WebPush, Webhook).
* **Observability** ‚Üí centraliza logs, m√©tricas e tracing.
* **Client** ‚Üí consome tudo via Dashboard ou integra√ß√µes.

---

Quer que eu adicione **√≠cones espec√≠ficos de provedores (AWS, GCP, Azure)** ou uma **vers√£o separada por dom√≠nio (coleta / processamento / entrega)**?
Posso gerar uma variante visual ‚ÄúAWS architecture style‚Äù em Mermaid tamb√©m.
